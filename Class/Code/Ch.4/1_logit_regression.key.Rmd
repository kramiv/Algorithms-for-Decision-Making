---
title: "Logistic regression in tidymodels"
author: "Jaime Davila"
date: "3/7/2022"
output:
  pdf_document: default
  html_document: default
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=FALSE, warning=FALSE, message=FALSE)
library(tidyverse)
```

# Introduction

Let's start by loading an old friend of ours, the `Default` dataset (remember Homework 3?)

```{r}
library(ISLR2)
data(Default)
default.tbl <- tibble(Default)
```

We are interested in predicting whether a person would go on *default* (that is, would not pay back a loan) given the following information:

* `balance` (How much does the person owe?)
* `income` (How much does the person earn?)
* `student` (Is the person a student?)

0. How many observations does this dataset have? How many defaults and non-defaults? How many defaults by student status?

```{r}
dim(default.tbl)
table(default.tbl$default)
table(default.tbl$default, default.tbl$student)
```

1. Create a boxplot of `balance` across people who default or not. What do you observe? What do you observe when you facet the boxplot by `student`?

```{r}
ggplot(default.tbl, aes(x=default, y=balance, fill=default)) +
  geom_boxplot()

ggplot(default.tbl, aes(x=default, y=balance, fill=default)) +
  geom_boxplot() +
  facet_grid(.~student)
```

2. How about the effect of `income` on defaulting? Does it change according to `student` status?

```{r}
ggplot(default.tbl, aes(x=default, y=income, fill=default)) +
  geom_boxplot()

ggplot(default.tbl, aes(x=default, y=income, fill=default)) +
  geom_boxplot() +
  facet_grid(.~student)
```

3. Load `tidymodels` and create a training dataset using $8000$ observations and a testing dataset using $2000$ observations. Make sure to call your training dataset `default.train.tbl` and your testing dataset `default.test.tbl`

```{r echo=TRUE}
set.seed(12345)
```

```{r}
library(tidymodels)
tidymodels_prefer()

default.split <- initial_split(default.tbl, prop=0.8)
default.train.tbl <- training(default.split)
default.test.tbl <- testing(default.split)
```

# Modeling probabilities with linear models

Let's start by trying to predict the default using a linear model whose input variable is `balance`, that is 

$$ y = \alpha_0 + \alpha_1 \times balance$$
In homework 3 we learned that using linear models in this setting creates a number of issues for classification, among them the fact that we are not guaranteed that the prediction will correspond to a probability (a number between `0` and `1`)

One way to overcome this is to use the log odds on our response variable. The log odds $y$ of an event with probability $p$ is defined as

$$\tilde y :=\log \left(\frac{p}{1-p}\right)$$

Hence, if $\tilde y$ represents the log odds, we can invert this expression to get the probability.

$$p=\frac{e^{\tilde y}}{1+e^{\tilde y}}=\frac{1}{1+e^{-\tilde y}}$$

# Logistic regression using `tidymodels`

Fortunately for us, logistic models are readily available in R. We can create such a model on the training dataset using the following code:

```{r echo=TRUE}
logit.model <- logistic_reg() %>%
  set_engine("glm") %>%
  set_mode("classification")

default.recipe <- 
  recipe(default ~ balance, data=default.train.tbl)

logit.wflow <- workflow() %>%
  add_recipe(default.recipe) %>%
  add_model(logit.model) 

logit.fit <- fit(logit.wflow, default.train.tbl)
```

Finally we can predict the probability of defaulting on the testing dataset or simply predict whether someone would go on default or not

```{r}
predict(logit.fit, default.test.tbl, type="prob")
predict(logit.fit, default.test.tbl)
```

4. Plot the predicted probability of defaulting (using the logit model) as a function of `balance`.

```{r}
augment(logit.fit, default.test.tbl) %>%
  ggplot(aes(balance,.pred_Yes))+
  geom_line()
```

5. How many observations are predicted to default in your testing dataset? How many of your predictions are wrong?

```{r}
new.default.test.tbl <- augment(logit.fit, default.test.tbl)

table(new.default.test.tbl$.pred_class)
mean(new.default.test.tbl$.pred_class 
     != new.default.test.tbl$default)
```

5. `yardstick` allows you to evaluate the performance of your classification model in many different ways. Consult https://www.tmwr.org/performance.html#binary-classification-metrics and do the following:

a. Calculate the confusion matrix of your model. Is your model making more errors on people that go on default or not?

```{r}
augment(logit.fit, default.test.tbl) %>%
  conf_mat(truth = default, estimate = .pred_class)
```

b. Define how `accuracy` is defined and calculate it for your model.

```{r}
augment(logit.fit, default.test.tbl) %>%
  accuracy(truth = default, estimate = .pred_class)
```

c. Define `specificity`, `sensitivity`, `ROC`, and `AUC`. Plot the ROC curve and calculate the AUC of your model

```{r}
model_curve <- roc_curve(new.default.test.tbl, default, .pred_No)
autoplot(model_curve)

roc_auc(new.default.test.tbl, default, .pred_No)
```

7. (*Optional*) Calculate the AUC and plot the ROC for the logistic regression model that takes into account `balance`, `income` and `student`.

```{r}
default.recipe <- 
  recipe(default ~ balance+income+student, data=default.train.tbl)

logit.wflow <- workflow() %>%
  add_recipe(default.recipe) %>%
  add_model(logit.model) 

logit.fit <- fit(logit.wflow, default.train.tbl)

augment(logit.fit, default.test.tbl) %>%
  conf_mat(truth = default, estimate = .pred_class)

new.default.test.tbl <- augment(logit.fit, default.test.tbl)
model_curve <- roc_curve(new.default.test.tbl, default, .pred_No)
autoplot(model_curve)

roc_auc(new.default.test.tbl, default, .pred_No)
```

8. (*Optional*) Plot the decision boundary for the logistic regression model with inputs of balance, income and student.

```{r}
grid.tbl <-  expand_grid(student=factor(c("Yes","No")),
                         balance=seq(0,3000,30), 
                         income=seq(0,80000,30)) 

augment(logit.fit, grid.tbl) %>%
  ggplot(aes(balance, income, z=.pred_No,fill = .pred_No)) +
    geom_raster() +
    stat_contour(breaks=c(0.5), color="black")+
    facet_grid(student~.)+
    scale_fill_viridis_b()

```


