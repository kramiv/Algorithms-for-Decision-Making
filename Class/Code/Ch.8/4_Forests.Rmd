---
title: "Random Forests"
author: "Jaime Davila"
date: "4/27/2021"
output:
  pdf_document: default
  html_document: default
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
#knitr::opts_chunk$set(echo=FALSE, warning=FALSE, message=FALSE, fig.show="hide", results=FALSE)
knitr::opts_chunk$set(warning=FALSE, message=FALSE)
library(tidyverse)
library(tidymodels)
library(dslabs)
tidymodels_prefer()
```


# Introduction

Today we will be using a small subset of the MNIST dataset, by selecting 1000 digits for both training and testing:

```{r echo=TRUE}
mnist <- read_mnist("~/Mscs 341 S22/Class/Data")
set.seed(2022)
index <- sample(nrow(mnist$train$images), 1000)
digit.train.tbl <- as_tibble (mnist$train$images[index,]) %>%
  mutate(digit = factor(mnist$train$labels[index]))

index <- sample(nrow(mnist$test$images), 1000)
digit.test.tbl <- as_tibble (mnist$test$images[index,]) %>%
  mutate(digit = factor(mnist$test$labels[index]))
```

And as before let's make a couple of functions to plot particular digits from our dataset

```{r echo=TRUE, fig.show='asis'}
plotImage <- function(dat,size=28){
  imag <- matrix(dat,nrow=size)[,28:1]
  image(imag,col=grey.colors(256), xlab = "", ylab="") 
}

plot_row <- function(tbl) {
  ntbl <- tbl %>%
    select(V1:V784)
  plotImage(as.matrix(ntbl))
}
```

```{r echo=TRUE, fig.show='asis'}
# Plot the 100th digit from training
plot_row(digit.train.tbl[100,])
# Plot the 13th digit from testing
plot_row(digit.test.tbl[12,])
```

As in our last homework, we are interested in doing multi-digit classification.

# Maximal classification trees

1. a. Fill out the details of the function `create_rtree` which creates a maximal tree for doing multi-digit classification. The function receives a training dataset and returns a fitted regression tree. Create a regression tree called `digit.rtree.model` using the function `create_rtree` on  your training dataset.

```{r echo=TRUE}
create_rtree <- function (train.tbl) {
  
}
```

b. Calculate the accuracy and confusion matrix of `digit.rtree.model` using your testing dataset


I got curious about why some 4's get classified as 9's so I decided to take a look:

```{r}
miss.4s.tbl <- augment(digit.rtree.model,digit.test.tbl) %>% 
  filter(digit==4 & .pred_class==9)

plot_row(miss.4s.tbl[2,])
plot_row(miss.4s.tbl[6,])
plot_row(miss.4s.tbl[9,])
plot_row(miss.4s.tbl[13,])
plot_row(miss.4s.tbl[8,])
```


On a different note, we can define a function that will allow us to plot the pixel importance for a particular model.

```{r echo=TRUE}
create_image_vip <- function(model.fit) {
  # Creates the importance image
  imp.tbl <- model.fit %>%
    extract_fit_engine() %>%
    vip::vi() %>%
    mutate(col=as.double(str_remove(Variable,"V")))
  mat <- rep(0, 28*28)
  mat[imp.tbl$col] <- imp.tbl$Importance
  mat
}
```

Let's use this function to show the important pixels for our model:

```{r echo=TRUE, fig.show='asis'}
create_image_vip(digit.rtree.model) %>%
  plotImage()
```

# Using bootstrapping

Bootstrapping allows us to create new training datasets by sampling with replacement from our training dataset. Let's create 3 bootstrap samples from our original training dataset:

```{r echo=TRUE, fig.show="asis"}
set.seed(12345)
bootstrap.split <- bootstraps(digit.train.tbl, times=3)
bootstrap.split
```

Notice how `bootstrap.split` is a tibble. Also note that we can access the 2nd bootstrap by using the command:

```{r echo=TRUE, results=TRUE}
analysis(bootstrap.split$splits[[2]])
```

2. Fit classification trees to each bootstrapped training dataset and plot the variable importance as an image for each model. Are there pixels that are common to the three models?


# Remembering bagging

In bagging we combine a fixed amount of trees which are trained on bootstraps of our training dataset. Let's create a bagging model by leveraging the function `use_ranger` which generates code that we can copy/paste to create our model.

```{r echo=TRUE, results=TRUE}
library(usemodels)
use_ranger(digit~., data=digit.train.tbl, tune=FALSE)
```

We will modify the generated code as follows:

* We will be using `trees=100` so that our code runs faster
* We will be using `mtry=784` so that make sure that we are using all of our variables for each of our classification trees.
* We will add the parameter `importance="impurity"`, so that we can determine the importance of the variables in our model. 

```{r echo=TRUE}
ranger_recipe <- 
  recipe(formula = digit ~ ., data = digit.train.tbl) 

ranger_spec <- 
  rand_forest(trees = 100, mtry=784) %>% 
  set_mode("classification") %>% 
  set_engine("ranger",importance = "impurity")  

ranger_workflow <- 
  workflow() %>% 
  add_recipe(ranger_recipe) %>% 
  add_model(ranger_spec) 
```

Finally let's fit our model on the training dataset and calculate our accuracy on the testing dataset. Notice how our bagging model improves significantly over individual maximal classification trees

```{r echo=TRUE, results=TRUE}
digit.bag.model <- fit(ranger_workflow, digit.train.tbl)

augment(digit.bag.model, digit.test.tbl) %>%
  accuracy(truth=digit, estimate= .pred_class)

augment(digit.bag.model, digit.test.tbl) %>%
  conf_mat(truth=digit, estimate= .pred_class)
```

And let's look at the 4's that get classified as 9's in this model

```{r fig.show="hide"}
miss.4s.tbl <- augment(digit.bag.model,digit.test.tbl) %>% 
  filter(digit==4 & .pred_class==9)

for (i in 1:nrow(miss.4s.tbl)) {
  print(plot_row(miss.4s.tbl[i,]))
}
```

Notice that the variable importance in a bag is the sum of the variable importance across all splits for all  trees. We can plot our variable importance for maximal trees and for our bagging model below. Notice how in bagging more pixels end up being used, however some pixels in the middle of the image are used repetitively

```{r fig.show="asis", echo=TRUE}
create_image_vip(digit.rtree.model) %>%
  plotImage()

create_image_vip(digit.bag.model) %>%
  plotImage()
```

# Forests

Let's remember that the standard deviation of  $\frac{(X_1 + \dots + X_n)}{n}$ is $\frac {\sigma} {\sqrt n}$ if $X_1, \dots, X_n$ are *independent*. In practice the outcome of a maximal tree can be quite correlated with the outcome of a different maximal tree since some variables are dominant when we do splits over our training data (think for examples the pixels in the center of our digit images)

In *random forests* we try to decorrelate each of these trees by selecting a random fraction of the variables at each level of the tree, to force different trees to not be related to each other. In practice the number of variables can be selected by using the parameter `mtry` and usually is:

* $\frac{n}{3}$ for regression trees
* $\sqrt{n}$ for classification trees.

This can be implemented using the following code

```{r echo=TRUE}
ranger_recipe <- 
  recipe(formula = digit ~ ., data = digit.train.tbl) 

ranger_spec <- 
  boost_tree(trees = tune(), learn_rate = tune()) %>% 
  set_mode("classification") %>% 
  set_engine("xgboost")  

ranger_workflow <- 
  workflow() %>% 
  add_recipe(ranger_recipe) %>% 
  add_model(ranger_spec) 

digit.forest.model <- fit(ranger_workflow, digit.train.tbl)
```

Notice that we can calculate as before our accuracy and confusion matrix and we get an improvement over our bagging approach:

```{r echo=TRUE, results=TRUE}
augment(digit.forest.model, digit.test.tbl) %>%
  accuracy(truth=digit, estimate= .pred_class)

augment(digit.forest.model, digit.test.tbl) %>%
  conf_mat(truth=digit, estimate= .pred_class)
```

And let's check the 4's that get classified as 9's in this last model

```{r fig.show="hide"}
miss.4s.tbl <- augment(digit.forest.model,digit.test.tbl) %>% 
  filter(digit==4 & .pred_class==9)

for (i in 1:nrow(miss.4s.tbl)) {
  print(plot_row(miss.4s.tbl[i,]))
}
```


Finally, let's plot our variable importance for our three methods:

```{r fig.show="asis", echo=TRUE}
create_image_vip(digit.rtree.model) %>%
  plotImage()

create_image_vip(digit.bag.model) %>%
  plotImage()

create_image_vip(digit.forest.model) %>%
  plotImage()
```

Notice that when compared to our bagging model, our random forest starts using more pixels in our image.


# Tissue classification

In the next set of exercises we will be issue the `tissue_gene_expression` dataset.

```{r echo=TRUE, results=TRUE}
library(dslabs)
data(tissue_gene_expression)

tissue.gene.tbl <- tissue_gene_expression$x %>%
  as_tibble() %>%
  mutate(tissue = as.factor(tissue_gene_expression$y))

set.seed(4272022)
tissue.split <- initial_split(tissue.gene.tbl, prop=0.5)
tissue.train.tbl <- training(tissue.split)
table(tissue.train.tbl$tissue)
tissue.test.tbl <- testing(tissue.split)
```

3.  Create an optimal classification tree to predict tissue type by selecting the optimal `cp` using 10-fold cross-validation. Calculate the accuracy and confusion matrix using your testing dataset. What do you observe happening for placenta?

4. From the previous point we notice that missclassified all of the placentas. Note that the number of placentas in our dataset is six (four of them in training) , and that, by default, `rpart` requires 20 observations before splitting a node. Hence it is not possible to have a leaf where placentas are the majority when using our default `min_n`. Rerun the analysis in 3 by setting up `min_n=1`. Does the accuracy increase? Look at the confusion matrix again. Calculate the top-5 most important features by using `vip`. Check in `genecards` a couple of the genes that you obtain and argue if they make biological sense.

5. Repeat 4, by using a bagging model with `100` trees (notice  `min_n=1`). 

6. Repeat 5, using a random forest with 100 trees.

7. Repeat 6 but this time the optimal `mtry` using 10-fold cross validation. For values of `mtry` use at least 10 values from 50 to 200. Compare the top-5 most important variables with what you got in 5 and in 4.


