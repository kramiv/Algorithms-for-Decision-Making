---
title: "Using recipes in tidymodels"
author: "Jaime Davila"
date: "3/1/2022"
output:
  pdf_document: default
  html_document: default
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning=FALSE, message=FALSE)
library(tidyverse)
```

# Using recipes in  `tidymodels`

In today's class we will explore how to create better models by creating new variables from old ones. This process is sometimes called *feature engineering* and we will learn how to do using `recipes` from `tidymodels`. In this worksheet we will be covering most of the material from https://www.tmwr.org/recipes.html 

## Using the ames dataset

Let's start by loading the appropriate libraries, datasets and converting our variable `price` so that is in on log-scale. Also let's make sure that we create our testing and training dataset

```{r echo=TRUE}
library(tidymodels)
tidymodels_prefer()

library(modeldata)
data(ames)
ames <- ames %>%
  mutate(Sale_Price=log10(Sale_Price))

set.seed(12345)
ames.split <- initial_split(ames, prop=0.8)
ames.train <- training(ames.split)
ames.test <- testing(ames.split)
```

## Initial modeling

We are interested in predicting the price of the property adding  the following variables:

* `Neighborhood`

* `Gr_Liv_Area`, corresponding to the gross above-grade living area.

* `Year_built`

* `Bldg_type` corresponding to the building type

1. What is the type of each of these four variables? If a variable is categorical how many different values (levels) it has

```{r}
class(ames$Neighborhood)
levels(ames$Neighborhood)

class(ames$Gr_Liv_Area)
class(ames$Year_Built)

class(ames$Bldg_Type)
levels(ames$Bldg_Type)
```

2. Do a histogram of `Gr_Liv_Area`. How does this histogram looks  using a log scale?

```{r}
ggplot(ames, aes(x=Gr_Liv_Area))+
  geom_histogram()

ggplot(ames, aes(x=Gr_Liv_Area))+
  geom_histogram()+
  scale_x_log10()
```

## Creating a recipe

A recipe is a collection of steps for preprocessing a dataset. Our initial recipe will include the following steps:

* We would like to make it explicit that we are modeling the `Sale_Price` (response variable) based on `Latitude` and `Longitude`, `Gr_Liv_area`, and `Bldg_type` (explanatory variables)

* We would like to use a log scale for `Gr_Liv_Area`

* We would like to transform all of our categorical variables into indicator variables.

```{r echo=TRUE}
ames.recipe <- 
  recipe(Sale_Price ~ Longitude + Latitude + Gr_Liv_Area + 
            Bldg_Type, data=ames.train) %>%
  step_log(Gr_Liv_Area, base=10) %>%
  step_dummy(all_nominal_predictors())
ames.recipe
```

Once we created the recipe we can use in conjunction with a linear model, add it to a workflow and fit our workflow using our training dataset

```{r echo=TRUE}
lm.model <- linear_reg() %>%
  set_engine("lm")

lm.wflow <- workflow() %>%
  add_recipe(ames.recipe) %>%
  add_model(lm.model) 

lm.fit <- fit(lm.wflow, ames.train)
```

3. 
a. What is the $R^2$ of the linear model you created? How do you interpret this value?

```{r}
glance(lm.fit)$r.squared
```

b. Interpret the coefficients corresponding to:

* The living area of the house.
* The type of building.

```{r}
model.coef <- tidy(lm.fit)
model.coef
```

4. Evaluate your model using the testing dataset. What is the MSE on this dataset?

```{r}
new.ames.test <- lm.fit %>%
  augment(new_data = ames.test)
rmse_vec(new.ames.test$Sale_Price, new.ames.test$.pred)^2
```

5. Add `Year_Built` as an input variable in your existing recipe. What is the $R^2$ of your model? What is the MSE on the testing dataset?

6. Add `Neighborhood` as an input variable recipe to your model from 5. What is the $R^2$ of your model? What is the MSE on the testing dataset?



7. 
a. Summarize and sort the number of observations in each neighborhood. How many many neighborhoods have less than 20 observations? 

b. Consult the documentation for `step_other` and add a step to your recipe where you collapse neighborhoods with less than 1% of your data. Make sure to add this step before the `step_dummy` command.

c. Rerun your workflow and your model. How do you interpret the coefficient of the model associated with the collapsed set of neighborhoods? What is the MSE of this new model?

8. 
a. What two features are you planning to use for your first challenge?

b. Using the MNIST dataset select a couple of instances of the digits assigned to your group. Calculate the two features on those instances. Are the two features similar across the two different types of digits?

