---
title: "Algorithms for Decision Making: Exam 1"
author: "Ivana K."
date: "3/24/22"
output:
  pdf_document: default
  html_document: default
  word_document: default
editor_options:
  chunk_output_type: console
---
\newcommand{\pledgeline}{
\setlength{\unitlength}{1in}
\begin{picture}(6, .125)
\put(0,0){\line(1,0){4}}
\end{picture}
}

\newcommand{\ret}{
\vspace{1cm} }
\newcommand{\reta}{
\vspace{.5cm} }
\newcommand{\retb}{
\vspace{2.5cm} }
\newcommand{\retc}{
\vspace{3.2cm} 
}


```{r setup, echo=FALSE, warning=FALSE, message=FALSE}
knitr::opts_chunk$set( warning=FALSE, message=FALSE)
library(tidyverse)
library(tidymodels)
library(kknn)
library(dslabs)
library(discrim)
tidymodels_prefer()
```

### Exam 1 Guidelines

- You have the entire class time (80 minutes) to complete this exam.  

- Please make sure to save **immediately** your work in your submit folder. By the end of class time save the last version of your work and **don't** modify it afterwards.

- You are to work completely independently on the exam. 

- You are allowed to use your class notes, moodle, worksheets, homeworks, textbooks, plus the "Help" feature from Rstudio.

- You **are not** permitted to do web searches.

- Please silence your cell phone.  Place it and any other connected devices in your bag and do not access them for any reason.

For questions that ask for interpretations and explanations, usually no more than a sentence or two is needed for justification.  Be thorough, but do not “brain dump”.  Notice that three sections of this exam are independent and that you can complete later sections successfully whether or not earlier sections are correct. 

Do not spend too long on any one question. If you are not sure about an answer, write a note detailing your concern.


**PLEDGE:**  I pledge on my honor that I have neither received nor given assistance during this exam nor have I witnessed others receiving assistance, and I have followed the guidelines as described above.  

Ivana Kramarevsky

\vspace{3mm}

**SIGNATURE:** \pledgeline

$\bigcirc$ I have intentionally not signed the pledge.

\vspace{3mm}















# The Weather in Minnesota (40 points)

It is spring in Minnesota and we are interested on predicting what month of the year we are living based on the outside temperature. To do that let's load our testing and training datasets

```{r echo=TRUE}
month.levels <-  c("Jan","Feb","Mar")
temp.train.tbl <- read_csv("~/Mscs 341 S22/Class/Data/mn_weather.train.csv") %>%
  mutate(month=factor(month, month.levels))
temp.test.tbl <- read_csv("~/Mscs 341 S22/Class/Data/mn_weather.test.csv") %>%
  mutate(month=factor(month, month.levels))
```

## Question 1 (15 points)

Do a boxplot using `temp.train.tbl` with the distribution of the temperature across the first 3 months of the year. Calculate the mean and standard deviation of the temperature for each of the 3 months. Based on this information, which method would you choose between `lda` and `qda` to predict the month based on the temperature? Justify your answer.

classification

```{r}
plot.tbl <- temp.train.tbl %>%
  filter(month == "Jan" | month == "Feb" | month == "Mar")
plot.tbl %>%
  ggplot() +
    geom_boxplot(aes(month, temp))

small.plot.tbl <- plot.tbl %>%
  group_by(month) %>%
  summarize(mean_by_month = mean(temp),
            sd_by_month = sd(temp),
            month = month) %>%
  print(n = 1000)
```
Jan = 24.2       10.3 

Feb = 29.2        5.78

Mar = 34.9        4.01

If more time: get rid of extra copies of the same row. There's code for this on the dyplr cheat sheet - forgot where it is :|

I think that for these 3 months, I would use a linear estimate. I would use lda. I think the standard deviation shows that temperature is very variable and, overall, does not neatly follow a quadratic shape. Not sure.


## Question 2 (15 points)

Using `tidymodels()` create the model you chose in `Question 1` (either `lda` or `qda`) for predicting the month based on the temperature. Using your testing dataset, plot the predicted probability of a temperature corresponding to January, February or March in a single graph. How do you interpret this plot and what are the classification boundaries for each month? Using the information from this plot on which month will your model be making more mistakes?

```{r}
lda.model <- discrim_linear() %>%
set_engine("MASS") %>%
set_mode("classification")
recipe <- recipe(month ~ temp, data=temp.train.tbl)#I think we train data for all months?
lda.wflow <- workflow() %>%
add_recipe(recipe) %>%
add_model(lda.model)
lda.fit <- fit(lda.wflow, temp.train.tbl)
#augment(lda.fit,temp.test.tbl) %>%
#conf_mat(month, .pred_class)
```

**********
plot the predicted probability of a temperature corresponding to January, February or March in a single graph. 
**********

grid.tbl <- expand_grid(magnitude=seq(-10,20, by=0.3),
temp = seq(-10,50, by=1))

augment(lda.fit, grid.tbl) %>%
  filter(month == "Jan" | month == "Feb" | month == "Mar") %>%
  full_join(small.plot.tbl) %>%
  ggplot(aes(month,temp, fill=.pred_class)) +
  geom_raster()

  
       
how to plot for one variable?
******








## Question 3 (10 points)

Calculate the sensitivity and specificity of your model and interpret them in the context of your problem. Based on the confusion matrix, on which month does your model make more mistakes?

# Wrangling with Terminator 2 (20 points)

`Movielens` is a dataset containing user provided feedback from different movies. You can find more information about this dataset using `?movielens`. We can load this dataset by doing:

```{r echo=TRUE}
data(movielens)
movielens.tbl <- tibble(movielens)
```

We are interested in creating a simple recommendation system for the classic 90s movie and one of Prof. Davila's favorites, "Terminator 2: Judgment Day"

## Step one (5 points)

What are the movieId and genres corresponding to "Terminator 2: Judgment Day"? Do a histogram of the user ratings for this movie.

```{r}
movielens.tbl %>%
  filter(title == "Terminator 2: Judgment Day") %>%
  select(movieId, genres, rating) %>%
  ggplot(aes(x = as.factor(rating))) +
    geom_histogram(stat="count")
```
movieId is 589

genres are Action|Sci-fi

## Step two (5 points)

Create a table with the average movie ratings for each user. Also, create a table with the average rating for movies with genre "Action|Sci-Fi" for each user.

```{r}
# movieId title     year genres       userId rating timestamp
avg.rating.tbl <- movielens.tbl %>%
  group_by(userId) %>%
  summarize(avg.rating = mean(rating))
avg.rating.tbl
```

```{r}
avg.action.scifi.tbl <- movielens.tbl %>%
  filter(genres == "Action|Sci-Fi") %>%
  group_by(userId) %>%
  summarize(avg.action.scifi = mean(rating))
avg.action.scifi.tbl
```

## Step three (10 points)

Create a table `terminator2.movie.tbl` with columns:

* `userId`
* The average rating of all movies for that `userId`.
* The average rating of all movies in the "Action|Sci-Fi" for that userId.
* The rating that user gave to Terminator 2

Make sure to remove rows that have "NA" in either of those columns

```{r}
full_join(avg.action.scifi.tbl, avg.rating.tbl, by = "userId") %>%
  left_join(movielens.tbl, by = "userId") %>%
  filter(title == "Terminator 2: Judgment Day") %>%
  select(userId, avg.rating, avg.action.scifi, rating) %>%
  filter(!is.na(avg.action.scifi)) %>%
  filter(!is.na(rating)) %>%
  filter(!is.na(avg.rating))
```

# Rating Terminator 2 (40 points)

Make sure that the tibble you obtained from the previous point has 237 observations and 4 variables. In case you ran into problems you can use the following code:

```{r echo=TRUE}
terminator2.movie.tbl <- read_csv("~/Mscs 341 S22/Class/Data/movies.csv")
dim(terminator2.movie.tbl)
```

Let's create our testing and testing dataset

```{r echo=TRUE}
set.seed(55057)
terminator2.split <- initial_split(terminator2.movie.tbl)
terminator2.train.tbl <- training(terminator2.split)
terminator2.test.tbl <- testing(terminator2.split)
```

## Linear models (20 points)

Using `tidymodels()` create a linear model to predict the rating of Terminator 2 based on `avg.rating` and `avg.action.scifi`. How do you interpret the coefficients of your linear model? What is your `rmse` and $R^2$ in your testing dataset?

```{r}
lm.model <- linear_reg() %>%
  set_engine("lm")

lm.wflow <- workflow() %>%
  add_model(lm.model) %>%
  add_formula(rating ~ avg.rating + avg.action.scifi)

lm.fit <- fit(lm.wflow, terminator2.train.tbl)
```

```{r}
lm.fit %>%
  extract_fit_engine() %>%
  tidy()

#lm.fit %>%
#  extract_fit_engine() %>%
#  glance()
```
coefficients: 
avg.rating = -0.154
avg.action.scifi = 0.767

Interpretation of coefficients: A lower average rating predicts a higher Terminator rating with a weak correlation. Also, a higher average sci-fi rating predicts a higher Terminator rating.

```{r}
augment(lm.fit, terminator2.test.tbl) %>%
  rsq(truth = rating, estimate = .pred)
```
R^2 = 0.789

```{r}
ames.test <- lm.fit %>%
  augment(new_data = terminator2.test.tbl)
rmse_vec(ames.test$rating, ames.test$.pred)^2
```
rmse = [1] 0.1920836

## KNN models (20 points)

Using `tidymodels()` create a KNN model to predict the rating of Terminator 2 based on `avg.rating` and `avg.action.scifi`. Create a 10-fold cross-validation set and use it to find the optimal `neigbors` by minimizing the `rmse`. Describe in your own words how to construct the 5th training and testing dataset from your cross-validation set. Calculate the `rmse` and $R^2$ of your model in your testing dataset and compare it with the linear model from the previous point.

```{r echo=TRUE}
set.seed(55057)

knn.model <- nearest_neighbor(neighbors = tune()) %>%
set_engine("kknn") %>%
set_mode("regression")
recipe <- recipe(rating ~ avg.rating + avg.action.scifi, data=terminator2.train.tbl)
knn.wf <- workflow() %>%
add_recipe(recipe) %>%
add_model(knn.model)
# Neighbors optimization using CV
```

```{r}
best.neighbor <- select_best(tune.results,
neighbors, metric = "rsq")# this is 20
best.neighbor

knn.final.wf <- finalize_workflow(knn.wf, best.neighbor)
knn.final.fit <- fit(knn.final.wf, terminator2.train.tbl)
# Evaluation of model on the testing dataset
augment(knn.final.fit, terminator2.test.tbl) %>%
rsq(truth = rating, estimate = .pred)

```
Best neighbor value is k = 6

R^2 = 0.673

```{r}
t.test <- knn.final.fit %>%
  augment(new_data = terminator2.test.tbl)
rmse_vec(t.test$rating, t.test$.pred)^2
```
RMSE on testing dataset = [1] 0.2793049

The rmse is higher for this model compared to teh linear model which means that teh linear model is better.

# Extra Credit! (5 points)

Knit your document into a PDF and submit it though the Moodle webpage.

