---
title: "Bootstrapping"
author: "Jaime Davila"
date: "3/16/2022"
output:
  pdf_document: default
  html_document: default
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning=FALSE, message=FALSE)
library(tidyverse)
```

# Introduction

Once more we will be using our `1`, `2`, and `7` dataset.

```{r echo=TRUE}
digits <- c("1","2","7")
train.127.tbl <- read_csv("~/Mscs 341 S22/Class/Data/train.127.csv") %>%
  mutate(y=factor(y, levels=digits))
test.127.tbl <- read_csv("~/Mscs 341 S22/Class/Data/test.127.csv") %>%
  mutate(y=factor(y, levels=digits))
```

Let's train a QDA model using our training dataset:

```{r echo=TRUE}
library(tidymodels)
library(discrim)
tidymodels_prefer()

qda.model <- discrim_quad() %>%
  set_engine("MASS") %>%
  set_mode("classification")

recipe <- recipe(y ~ x_1 + x_2, data=train.127.tbl)

qda.wflow <- workflow() %>%
  add_recipe(recipe) %>%
  add_model(qda.model) 

qda.fit <- fit(qda.wflow, train.127.tbl)
```

1. We are interested in the proportion of `2`s that get correctly classified using our testing dataset. Calculate in an automated way this amount. *Hint* Create a confusion matrix and use the command `tidy()` to make into a tibble so that you can calculate this amount.

```{r}
conf.tbl <- augment(qda.fit, test.127.tbl) %>%
  conf_mat(truth = y, estimate = .pred_class) %>%
  tidy() %>%
  slice(4:6) %>%
  summarize(prop = 86/sum(value))
conf.tbl
#line 5 / line 4:6
#note the tidy way to do it in key.


```
proportion of correct 2's identified: 0.699

In principle the proportion of `2`s that gets correctly classified might change slightly depending on the training dataset. In the remainder of this worksheet we will assess the variability of this proportion by using a collection of different training datasets. 

To accomplish this we will be using the bootstrapping technique. A bootstrap dataset is obtained by sampling with replacement from the original dataset. First, we will train a model on each bootstrap dataset. The complement of our bootstrap dataset (this subset is usually called out-of-bag dataset) will be used as our testing dataset. Finally we will calculate our confusion matrix using our model and our testing dataset.

To implement this idea we will be using the function `bootstraps()` from `tidymodels`. The following exercises will guide you on how to do this.

2. Create 50 bootstraps from your training dataset using the function `bootstraps()` and store in a tibble called `bootstrap.tbl`. What is 10th bootstrap dataset? What is the 10th out-of-bag dataset? (*Hint* Use the functions `analysis()` and `assessment()`). What are the sizes of 3rd and 5th bootstrap datasets? What are the sizes of the 3rd and 5th out-of-bag datasets? Why are the sizes of the bootstrap datasets the same while the sizes of the out-of-bag datasets are different?

```{r}
#bootstraps()
#bootstrap.tbl
#10th bootstrap
#10th out of bag dataset - use analysis() and assessment()
#size of 3rd and 5th bootstrap datasets and out-of-bag datasets
#why are sizes of boostrap datasets the same while out of bag datasets different?
set.seed(12345)
bootstrap.tbl <- bootstraps(train.127.tbl, times = 50)#  removed times = 50

bootstrap.tbl$splits[[10]]
analysis(bootstrap.tbl$splits[[10]])#bootstrap dataset
assessment(bootstrap.tbl$splits[[10]])#out of bag dataset

analysis(bootstrap.tbl$splits[[3]])#bootstrap dataset
assessment(bootstrap.tbl$splits[[3]])#out of bag dataset

analysis(bootstrap.tbl$splits[[5]])#bootstrap dataset
assessment(bootstrap.tbl$splits[[5]])#out of bag dataset
```
all bootstrap datasets are the same size. *why?
but out of bag datasets are different. 
bootstrap samples with replacement. out of bag takes only unique values bootstrap hasn't taken.

use dim()

3. Define a function `calc_correct_twos_qda` that given a split will obtain testing and training datasets (remember to use `analysis()` and `assessment()`). The function will train a qda model using the testing dataset and calculate the proportion of missclassified 2s on the testing dataset. Test your function using a couple of the bootstraps from your previous point

```{r}
calc_correct_twos_qda <- function(split){
  train1.tbl <- analysis(split)
  test1.tbl <- assessment(split)
  
  qda.model <- discrim_quad() %>%
  set_engine("MASS") %>%
  set_model("classification")

  recipe <- (y~x_1+x_2, data = train1.tbl)
  
  qda.wflow <- workflow() %>%
    add_recipe(recipe) %>%
    add_model(qda.model) 
  qda.fit <- fit(qda.wflow, train1.tbl)
  
  conf.mat <- augment(qda.fit, test1.tbl) %>%
    conf_mat(truth = y, estimate = .pred_class) %>%
    tidy()
  
  sum <- conf.mat %>%
      slice(4:6) %>%
      summarize(sum = sum(value)) %>%
      pull(sum)
  
  value <- conf.mat %>%
      slice(5) %>%
      summarize(sum = sum(value)) %>%
      pull(sum)
  
  value/sum
}

calc_correct_twos_qda(bootstrap.tbl$splits[[10]])
```
I don't get where my error is. ???
compare with key.


Finally we need to apply the function `calc_correct_twos_qda()` on all the splits from `bootstrap.tbl`. Notice that the type of the column `splits` is a `list`, so we can use the function `map_dbl()`. `map_dbl(lst, f)` applies the function `f()` to all the elements of `lst` and outputs a `double` (that is why the suffix `_dbl`). We can do this as follows:

```{r echo=TRUE}
boots.values.tbl <- bootstrap.tbl %>% 
  mutate(prop.2s = map_dbl(splits, calc_correct_twos_qda))
```

4. Plot the histogram of the proportion of correctly classified 2s. Calculate the mean and standard deviation of this metric. Does the histogram, mean and standard deviation change a lot if you use a different set of 200 boostraps?


We will be using more bootstrapping after the break when we introduce more advance modeling approaches, so stay tuned!

# Remember:
# No HW for next week (3/21-3/25)
# Exam 1: In-class (3/24). Covers Ch. 2,3,4 and 5.1 from ISLR plus R-bootcamp (week 1 of class) and tidymodels!
# Sample in-class exam on Tu 3/22
