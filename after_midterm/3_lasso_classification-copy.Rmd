---
title: "Using LASSO for classification"
author: "Jaime Davila"
date: "4/10/2021"
output:
  pdf_document: default
  html_document: default
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
#knitr::opts_chunk$set(echo=FALSE, warning=FALSE, message=FALSE, fig.show="hide", results=FALSE)
knitr::opts_chunk$set(warning=FALSE, message=FALSE)
library(tidyverse)
library(tidymodels)
tidymodels_prefer()
library(glmnet)
library(vip)
```




Notes:
s = 1/lambda
big lambda = all coefficients near zero

# Introduction 

The package `dslabs` has the `tissue_gene_expression` dataset. This dataset contains the gene expression for 500 random genes (out of over 20,000 measured by a microarray) for 189 samples across seven different tissues. Let's load the dataset and take a look at some of the summary statistics:

```{r echo=TRUE, results=TRUE}
library(dslabs)
data(tissue_gene_expression)
str(tissue_gene_expression)

dim(tissue_gene_expression$x)
table(tissue_gene_expression$y)
```
List of 2
 $ x: num [1:189, 1:500] 9.83 9.63 9.69 9.99 9.58 ...
  ..- attr(*, "dimnames")=List of 2
  .. ..$ : chr [1:189] "cerebellum_1" "cerebellum_2" "cerebellum_3" "cerebellum_4" ...
  .. ..$ : chr [1:500] "MAML1" "LHPP" "SEPT10" "B3GNT4" ...
 $ y: Factor w/ 7 levels "cerebellum","colon",..: 1 1 1 1 1 1 1 1 1 1 ...
 
 y-variable is classification of the tissue (sum = 189 tissues)
 
This is useful for detecting cancer. 5% of cancer is metases. They don't know where the cancer originated. 

 
## Setting up our dataset

On a first iteration we are interested in creating a classifier function that will allow us to distinguish between `cerebellum` and `colon` based on their gene expression profile. We can do it as follows:

```{r echo=TRUE, results=TRUE}
tissue.levels<- c("cerebellum","colon")
sample.ids <- tissue_gene_expression$y %in% tissue.levels

tissue.gene.tbl <- tissue_gene_expression$x[sample.ids,] %>%
  as_tibble() %>%
  mutate(tissue = factor(tissue_gene_expression$y[sample.ids], levels=tissue.levels))
```

Note the tibble is very wide. More columns than rows. 

And let's divide dataset into training/testing datasets:

```{r echo=TRUE, results=TRUE}
set.seed(123456)
tissue.split <- initial_split(tissue.gene.tbl, prop=0.5)
tissue.train.tbl <- training(tissue.split)
tissue.test.tbl <- testing(tissue.split)
```

Finally, let's check the dimension of the training dataset:

```{r echo=TRUE, results=TRUE}
dim(tissue.train.tbl)
```

Notice that we only have 36 observations and we have 500 variables!

1. Talk to the people in your group and try to explain why logistic regression would not work using this training table.

All the little variables skew the line too much?
logistic regression can use only 2 variables. oh yeah. 
what about multiple logistic regression though?

mm. the columns/tissues are independent from each other?

We have too many columns. We would have to find 500 coefficients. 
There are 36 equations with 500 functions. 

Ohhhh. prof says "you have 500 beta variables to solve for and only 36 variables. Lasso will reduce the number of variables to solve for possible - will turn most beta variables to 0."

# Using LASSO for binary classification

We would like to build a model that will allow us to predict the tissue type based on the gene expression. Furthermore we would like to identify a small number of features (variables) to use in this model. Given LASSO's ability to identify a small subset of variables, seems this method is particularly well-suited for the problem.

Notice that we have used LASSO only for prediction so far, however `tidymodels` and `glmnet` allows us to use LASSO for classification by using the following syntax

```{r echo=TRUE, results=TRUE}
tissue.model <- 
  logistic_reg(mixture = 1, penalty=tune()) %>% 
  set_mode("classification") %>%#   Note: this is a classification problem, not a prediction problem.
  set_engine("glmnet")
```

2. Create a LASSO model and optimize the parameter $\lambda$ by following these steps

    a. Create a recipe `tissue.recipe` that would predict tissue type. Justify whether or not  you need to use `step_dummy()` as a step in your recipe? How about `step_normalize()`? Create a `tissue.wf` workflow by combining the recipe and the model.
    
step_dummy encodes factor variables in a numeric form. I think it is not necessary. 

I am not sure about step_normalize nor what it exactly does.

```{r}
head(tissue.train.tbl)$tissue
```

```{r echo=TRUE}
tissue.recipe <- 
  recipe(formula = tissue ~ ., data = tissue.train.tbl) %>% #  not sure what to add for formula = 
  #step_dummy(all_nominal_predictors()) %>% 
  step_normalize(all_predictors())
tissue.wf <- workflow() %>% 
  add_recipe(tissue.recipe) %>% 
  add_model(tissue.model)
```

    b. Create a 5 fold and a 10-fold cross validation dataset `tissue.fold`. Create a grid `penalty.grid` between -2 and 0 on the log-scale with 20 values. Use `tune_grid()` and plot the effect of the penalty in your classification accuracy. Notice that when using 10-fold you get an error message that says **"No event observations were detected in `truth` with event level `colon`"**. Can you explain what this error means? Would using 5-fold cross validation get rid of this error? Why?

```{r}
set.seed(1234)
tissue.fold.10 <- vfold_cv(tissue.train.tbl, v = 10)
tissue.fold.5 <- vfold_cv(tissue.train.tbl, v = 5)

penalty.grid.10 <-
  grid_regular(penalty(range = c(-2, 0)), levels = 20)
penalty.grid.10

tune.res.10 <- tune_grid(
  tissue.wf,
  resamples = tissue.fold.10, 
  grid = penalty.grid.10
)
autoplot(tune.res.10)
```
36 observations divided by 10 folds. The folds are uneven to each other. some 3, some 4 observations per fold. >some observations might be all cerebellums<

```{r}
penalty.grid.5 <-
  grid_regular(penalty(range = c(-2, 0)), levels = 20)
penalty.grid.5

tune.res.5 <- tune_grid(
  tissue.wf,
  resamples = tissue.fold.5, 
  grid = penalty.grid.5
)
autoplot(tune.res.5)
```
5 folds got rid of the error. 
```{r}
tissue.train.tbl$tissue
```
5 folds has a larger sample size so there isn't just the same of cerebellum or colon.

    c. Select the best penalty by using `select_by_one_std_err()` using accuracy as your metric and sorting in descending order the penalty parameter. Check the help of ?select_by_one_std_err and page 236 of ISLR to explain how the "one-standard-error" rule works. Use this parameter to finalize your workflow and fit. Calculate your confusion matrix using the testing dataset
    
```{r}
(best.penalty <- select_by_one_std_err(tune.res.10, metric = "accuracy", desc(penalty)))
```
"To find the least complex model within one std error of the numerically
 optimal model, the number of nearest neighbors are sorted from the largest
 number of neighbors (the least complex class boundary) to the smallest
 (corresponding to the most complex model)."
0.298

Prof: "when calculating ideal k-value, it is the average of 10 cross-validation MSE values. These values can be taken with 1 standard deviation of the mean for each point along this line. 1 standard deviation rule picks a point where values are still within one stndad deviation. 



```{r echo=TRUE, results=TRUE}
tissue.model <- 
  logistic_reg(mixture = 1, penalty=0.298 %>% 
  set_mode("classification") %>%#   Note: this is a classification problem, not a prediction problem.
  set_engine("glmnet")
```
```{r echo=TRUE}
tissue.recipe <- 
  recipe(formula = tissue ~ ., data = tissue.train.tbl) %>% #  not sure what to add for formula = 
  #step_dummy(all_nominal_predictors()) %>% 
  step_normalize(all_predictors())
tissue.wf <- workflow() %>% 
  add_recipe(tissue.recipe) %>% 
  add_model(tissue.model)
```
```{r}

```

MISSED SOLUTION






















    d. Determine which coefficients in your LASSO model are non-zero. Do a quick google search for "GPM6B genecards". Does it make sense that this gene distinguishes between cerebellum and colon? Plot the values of these two genes in your training and testing dataset? Are the values of these two genes very different across the two tissue types?

```{r}
tidy(TISSUE.FINAL.FIT) %>% filter(estimate!=0)
# >:(

#slow down and post the key please
library(gridExtra)
gg1 <- ggplot(tissue.train.tbl, aes(x = CLIP3, y = GPM6B, color = tissue, shape = tissue)) +
  geom_point()f
```
MISSED CODE HERE TOO








# Multiple tissue classification

Now that we gained some confidence in distinguishing between two tissues, we would like to create a more complex classifier. First, let's take a look at the number of tissues in our dataset

```{r echo=TRUE, results=TRUE}
table(tissue_gene_expression$y)
```

It seems we don't have enough placenta tissues in our dataset, so we will exclude them from our dataset.

```{r echo=TRUE, results=TRUE}
placenta.idx <-which(tissue_gene_expression$y=="placenta")
tissue_gene_expression$x <- tissue_gene_expression$x[-placenta.idx,]
tissue_gene_expression$y <- droplevels(tissue_gene_expression$y[-placenta.idx])

multiple.tissue.gene.tbl <- tissue_gene_expression$x[-placenta.idx,] %>%
  as_tibble() %>%
  mutate(tissue = droplevels(tissue_gene_expression$y[-placenta.idx]))

table(multiple.tissue.gene.tbl$tissue)
```

And create a testing/training dataset

```{r echo=TRUE, results=TRUE}
set.seed(6543)
tissue.split <- initial_split(multiple.tissue.gene.tbl, prop=0.5)
multiple.tissue.train.tbl <- training(tissue.split)
table(multiple.tissue.train.tbl$tissue)
multiple.tissue.test.tbl <- testing(tissue.split)
table(multiple.tissue.test.tbl$tissue)
```

Finally we can set up our model by making use of `multinom_reg()`

```{r echo=TRUE, results=TRUE}
tissue.model <- 
  multinom_reg(mixture = 1, penalty=tune()) %>% 
  set_mode("classification") %>% 
  set_engine("glmnet")
```







3. Create a LASSO model and use 5-fold cross validation and `select_by_one_std_err()` to determine the optimal penalty. What is the accuracy of LASSO on the testing dataset? How does the confusion matrix look on the testing dataset?

```{r}
set.seed(1234)
multiple.tissue.fold 
```




4. 

    a. Using the command `tidy()` determine the non-zero coefficients of your model (please remove the constant terms).  How do you interpret these terms? How many non-zero coefficients correspond to each tissue?

    b. What is the gene that allows you to distinguish a liver? Do a google search of the gene plus genecards and see if it makes sense. Do a boxplot of the value of the gene across the tissues from your testing dataset and interpret it. Do a boxplot of the predicted probability of being a liver  across all the tissues from your testing dataset and interpret it.


5. 

    a. In your testing dataset there was a cerebellum that was missclassified as a kidney. Identify this observation and determine its predicted probability of being each distinct tissue.

    b. Using your testing dataset do a boxplot of the predicted probability of being a cerebellum and the predicted probability of being a kidney. Can you identify the misclassified sample in the two boxplots?

